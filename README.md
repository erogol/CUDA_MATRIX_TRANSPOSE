This repository includes different types of CUDA kernels, executing Matrix Transpose operation.

There are;

naive approach - each thread handles one entry of the matrix
shared memory - first pass the data to shared memory than transpose the matrix (BEST)
one of the book's example code.

For aim of studying and learning cuda, it might be useful to look at these variations. 

Shared Memory
Thread Syncronization
Cuda Event API 
  are the concepts that are instanced by these codes.
